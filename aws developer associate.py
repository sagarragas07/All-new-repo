#AWS Developer associate Exam preparation tips(by Tahseer):-notes link will be available below the video. 
#65questions 130min (15questions experimental) 100 to 1000 need 720+pass   150USD(50% off) 75USD    stephen maarek,jhon bounco,neel devias.    
#
#Development with AWS srvcs         32%
#Security                           26% 
#Deployment                         24%
#Troubleshooting & Optimization     18%
#
#Analytics:-
##Athena:-Athena:-serverless,interactive query platform,works on the data stored in s3,uses standard SQL & ANIS for quering data,supports variety of formats(CSV,Json,Avro,ORC(columnar),Parquet(columnar)),only pay for querying the data
#Athena quickly query Unstructured,semi-structured & structured data. uses Presto(a distributed  SQL engine for Big Data),Athena accessed by AWS console,Athena API,Athena CLI,JDBC connection. Integrated with Glue Data Catalog,integrates with Quicksight(BI Tool) for data visualization. 
#Athena populared due to:-Used by Data Analysts to Query large S3 data sets,No need to spin up servers or Hadoop Cluster. 
#Athena Use cases:-Analyzing cloudTrail/cloudfront/vpc/elb logs.integration through ODBC/JDBC with other visualization Tool. Ad-hoc logs analysis.is a srvc that enables data analysts to perform interactive queries in the web-based cloud from s3(used to query JSON in s3).serverless query srvc to analyze data stored in s3 (use standard SQL language to query the files) commonly used with AMZ quicksight for Reporting/Dashboards(use columnar data for cost-saving).#Athena will works on ad-hoc sql queries to find sentimental words in a statement and quicksight is used to create intelligent dashboards
##Kinesis:-makes it easy to collect,process & analyze streaming data in Real-time(ingest real-time data:-app logs,metrics,website clickstreams,IOT telemetry data..),real-time streaming model)(this srvcs can scale independently from our app)
#AMZ Opensearch srvc:-Amazon OpenSearch Service is a managed service that makes it easy to deploy, operate, and scale OpenSearch clusters in the AWS Cloud. Amazon OpenSearch Service supports OpenSearch and legacy Elasticsearch OSS (up to 7.10, the final open source version of the software). When you create a cluster, you have the option of which search engine to use. OpenSearch is a fully open-source search and analytics engine for use cases such as log analytics, real-time application monitoring, and clickstream analysis.Amazon OpenSearch Service provisions all the resources for your OpenSearch cluster and launches it. It also automatically detects and replaces failed OpenSearch Service nodes, reducing the overhead associated with self-managed infrastructures. You can scale your cluster with a single API call or a few clicks in the console.
#Application Integration:-
#AWS Appsync:-is used to collect the data and querie by using GraphQL languages on multiplle Databases,Apis,&micro services.(is a serverless GraphQL & pub/sub srvc)
#Amazon Event bridge:-Amazon EventBridge is a serverless event bus service that makes it easy to connect your applications with data from a variety of sources. EventBridge delivers a stream of real-time data from your own applications, software-as-a-service (SaaS) applications, and AWS services and routes that data to targets such as AWS Lambda. You can set up routing rules to determine where to send your data to build application architectures that react in real time to all of your data sources. EventBridge enables you to build event-driven architectures that are loosely coupled and distributed.
#Amazon SNS(simple notification srvc):-Amazon Simple Notification Service (Amazon SNS) is a managed service that provides message delivery from publishers to subscribers (also known as producers and consumers). Publishers communicate asynchronously with subscribers by sending messages to a topic, which is a logical access point and communication channel. Clients can subscribe to the SNS topic and receive published messages using a supported endpoint type, such as Amazon Kinesis Data Firehose, Amazon SQS, AWS Lambda, HTTP, email, mobile push notifications, and mobile text messages (SMS). 
#Amazon sqs(simple queue srvs):-Amazon Simple Queue Service (Amazon SQS) offers a secure, durable, and available hosted queue that lets you integrate and decouple distributed software systems and components. Amazon SQS offers common constructs such as dead-letter queues and cost allocation tags. It provides a generic web services API that you can access using any programming language that the AWS SDK supports.
#AWS Step function:-this makes it easy to coordinate the components of distributed applications as a series of steps in a visual workflow. You can quickly build and run state machines to execute the steps of your application in a reliable and scalable fashion(build serverless visual workflow to orchestrat your Lambda function)
#compute:-
#Amazon Ec2:-Amazon Elastic Compute Cloud (Amazon EC2) offers the broadest and deepest compute platform, with over 600 instances and choice of the latest processor, storage, networking, operating system, and purchase model to help you best match the needs of your workload. We are the first major cloud provider that supports Intel, AMD, and Arm processors, the only cloud with on-demand EC2 Mac instances, and the only cloud with 400 Gbps Ethernet networking. We offer the best price performance for machine learning training, as well as the lowest cost per inference instances in the cloud. More SAP, high performance computing (HPC), ML, and Windows workloads run on AWS than any other cloud. instance types(general purpose,compute optimized,memory optimized,memory optimized,Accelerated computing,storage optimized2,HPC optimized,)(pricing:-on-demand,saving plan,Reserved ins,spot ins,Dedicated hosts,on-demand capacity reservation) 
#Amazon Elastic Beanstalk(PAAS):-Elastic Beanstalk is a service for deploying and scaling web applications and services. Upload your code and Elastic Beanstalk automatically handles the deployment—from capacity provisioning, load balancing, and auto scaling to application health monitoring. Elastic Beanstalk supports applications developed in Go, Java, .NET, Node.js, PHP, Python, and Ruby. When you deploy your application, Elastic Beanstalk builds the selected supported platform version and provisions one or more AWS resources, such as Amazon EC2 instances, to run your application.
#AWS Lambda(FAAS):-AWS Lambda is a compute service that lets you run code without provisioning or managing servers.Lambda runs your code on a high-availability compute infrastructure and performs all of the administration of the compute resources, including server and operating system maintenance, capacity provisioning and automatic scaling, and logging. With Lambda, all you need to do is supply your code in one of the language runtimes that Lambda supports.You organize your code into Lambda functions. The Lambda service runs your function only when needed and scales automatically. You only pay for the compute time that you consume—there is no charge when your code is not running.
#AWS Serverless Application Model(AWS SAM):-The AWS Serverless Application Model (AWS SAM) is a toolkit that improves the developer experience of building and running serverless applications on AWS. AWS SAM consists of two primary parts:1)AWS SAM template specification – An open-source framework that you can use to define your serverless application infrastructure on AWS.  2)AWS SAM command line interface (AWS SAM CLI) – A command line tool that you can use with AWS SAM templates and supported third-party integrations to build and run your serverless applications.
#Container:-
#AWS Copilot:-AWS Copilot is a command-line interface (CLI) tool developed by Amazon Web Services (AWS) to simplify the process of building, deploying, and managing containerized applications on AWS. It is designed to streamline the workflow for developers, enabling them to quickly create and deploy containerized applications on AWS without needing to deal with the underlying infrastructure details.With AWS Copilot, you can create, configure, and deploy containerized applications using Docker and AWS Fargate. Fargate is a serverless compute engine for containers on AWS that eliminates the need to manage the underlying infrastructure. Copilot abstracts away many of the complexities associated with configuring and deploying containers, allowing developers to focus on writing code rather than managing infrastructure. AWS Copilot is a command-line interface (CLI) tool developed by Amazon Web Services (AWS) to simplify the process of building, deploying, and managing containerized applications on AWS. It is designed to streamline the workflow for developers, enabling them to quickly create and deploy containerized applications on AWS without needing to deal with the underlying infrastructure details.With AWS Copilot, you can create, configure, and deploy containerized applications using Docker and AWS Fargate. Fargate is a serverless compute engine for containers on AWS that eliminates the need to manage the underlying infrastructure. Copilot abstracts away many of the complexities associated with configuring and deploying containers, allowing developers to focus on writing code rather than managing infrastructure.
#Amazon ECS(Elastic container registry):-Amazon Elastic Container Registry (Amazon ECR) is an AWS managed container image registry service that is secure, scalable, and reliable. Amazon ECR supports private repositories with resource-based permissions using AWS IAM. This is so that specified users or Amazon EC2 instances can access your container repositories and images. You can use your preferred CLI to push, pull, and manage Docker images, Open Container Initiative (OCI) images, and OCI compatible artifacts
#Amazon ECS(Elastic container srvc):-Amazon Elastic Container Service (Amazon ECS) is a fully managed container orchestration service that helps you easily deploy, manage, and scale containerized applications. As a fully managed service, Amazon ECS comes with AWS configuration and operational best practices built-in. It's integrated with both AWS and third-party tools, such as Amazon Elastic Container Registry and Docker. This integration makes it easier for teams to focus on building the applications, not the environment. You can run and scale your container workloads across AWS Regions in the cloud, and on-premises, without the complexity of managing a control plane.Amazon ECS terminol
#Amazon EKS (Elastic Kubernetes srvc):-Amazon Elastic Kubernetes Service (Amazon EKS) is a managed Kubernetes service to run Kubernetes in the AWS cloud and on-premises data centers. In the cloud, Amazon EKS automatically manages the availability and scalability of the Kubernetes control plane nodes responsible for scheduling containers, managing application availability, storing cluster data, and other key tasks. With Amazon EKS, you can take advantage of all the performance, scale, reliability, and availability of AWS infrastructure, as well as integrations with AWS networking and security services. On-premises, EKS provides a consistent, fully-supported Kubernetes solution with integrated tooling and simple deployment to AWS Outposts, virtual machines, or bare metal servers. 
#Database:-
#Amazon Aurora:-Amazon Aurora (Aurora) is a fully managed relational database engine that's compatible with MySQL and PostgreSQL. You already know how MySQL and PostgreSQL combine the speed and reliability of high-end commercial databases with the simplicity and cost-effectiveness of open-source databases. The code, tools, and applications you use today with your existing MySQL and PostgreSQL databases can be used with Aurora. With some workloads, Aurora can deliver up to five times the throughput of MySQL and up to three times the throughput of PostgreSQL without requiring changes to most of your existing applications.Aurora includes a high-performance storage subsystem. Its MySQL- and PostgreSQL-compatible database engines are customized to take advantage of that fast distributed storage. The underlying storage grows automatically as needed. An Aurora cluster volume can grow to a maximum size of 128 tebibytes (TiB). Aurora also automates and standardizes database clustering and replication, which are typically among the most challenging aspects of database configuration and administration.Aurora is part of the managed database service Amazon Relational Database Service (Amazon RDS). Amazon RDS is a web service that makes it easier to set up, operate, and scale a relational database in the cloud.
#Amazon DynamoDB:-Amazon DynamoDB is a fully managed NoSQL database service that provides fast and predictable performance with seamless scalability. DynamoDB lets you offload the administrative burdens of operating and scaling a distributed database so that you don't have to worry about hardware provisioning, setup and configuration, replication, software patching, or cluster scaling. DynamoDB also offers encryption at rest, which eliminates the operational burden and complexity involved in protecting sensitive data.With DynamoDB, you can create database tables that can store and retrieve any amount of data and serve any level of request traffic. You can scale up or scale down your tables' throughput capacity without downtime or performance degradation. You can use the AWS Management Console to monitor resource utilization and performance metrics.DynamoDB provides on-demand backup capability. It allows you to create full backups of your tables for long-term retention and archival for regulatory compliance needs.You can create on-demand backups and enable point-in-time recovery for your Amazon DynamoDB tables. Point-in-time recovery helps protect your tables from accidental write or delete operations. With point-in-time recovery, you can restore a table to any point in time during the last 35 days. 
#Amazon ElasticCache:-Amazon ElastiCache allows you to seamlessly set up, run, and scale an in-memory cache in the cloud. ElastiCache is compatible with both Redis and Memcached. Boost your application performance and achieve microsecond latency by caching alongside your existing databases. ElastiCache is a popular choice for real-time use cases like caching, session stores, gaming, geo-spatial services, real-time analytics, and queuing.
#Amazon MemoryDB for Redis:-MemoryDB for Redis is a durable, in-memory database service that delivers ultra-fast performance. It is purpose-built for modern applications with microservices architectures.MemoryDB is compatible with Redis, a popular open source data store, enabling you to quickly build applications using the same flexible and friendly Redis data structures, APIs, and commands that they already use today. With MemoryDB, all of your data is stored in memory, which enables you to achieve microsecond read and single-digit millisecond write latency and high throughput. MemoryDB also stores data durably across multiple Availability Zones (AZs) using a Multi-AZ transactional log to enable fast failover, database recovery, and node restarts.Delivering both in-memory performance and Multi-AZ durability, MemoryDB can be used as a high-performance primary database for your microservices applications, eliminating the need to separately manage both a cache and durable database.
#Amazon RDS:-Amazon Relational Database Service (Amazon RDS) is a web service that makes it easier to set up, operate, and scale a relational database in the AWS Cloud. It provides cost-efficient, resizable capacity for an industry-standard relational database and manages common database administration tasks.
#Developer Tools:-
#AWS Amplify:-With AWS Amplify, building feature-rich, full-stack web and mobile apps has never been easier—from development to deployment. Get to market fast and scale as your business grows..Build full-stack web and mobile apps in hours,easy to start easy to scale.AWS Amplify is a complete solution that lets frontend web and mobile developers easily build, ship, and host full-stack applications on AWS, with the flexibility to leverage the breadth of AWS services as use cases evolve. No cloud expertise needed.
#AWS Cloud9:-AWS Cloud9 is a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser. It includes a code editor, debugger, and terminal. Cloud9 comes prepackaged with essential tools for popular programming languages, including JavaScript, Python, PHP, and more, so you don’t need to install files or configure your development machine to start new projects. Since your Cloud9 IDE is cloud-based, you can work on your projects from your office, home, or anywhere using an internet-connected machine. Cloud9 also provides a seamless experience for developing serverless applications enabling you to easily define resources, debug, and switch between local and remote execution of serverless applications. With Cloud9, you can quickly share your development environment with your team, enabling you to pair program and track each other's inputs in real time.
#AWS Cloudshell:-AWS CloudShell is a browser-based, pre-authenticated shell that you can launch directly from the AWS Management Console. You can navigate to CloudShell from the AWS Management Console a few different ways.You can run AWS CLI commands using your preferred shell, such as Bash, PowerShell, or Z shell. And you can do this without downloading or installing command line tools.
#AWS code artifact:-AWS CodeArtifact is a secure, highly scalable, managed artifact repository service that helps organizations to store and share software packages for application development. You can use CodeArtifact with popular build tools and package managers such as the NuGet CLI, Maven, Gradle, npm, yarn, pip, and twine. CodeArtifact helps reduce the need for you to manage your own artifact storage system or worry about scaling its infrastructure. There are no limits on the number or total size of the packages that you can store in a CodeArtifact repository.you can create a connection between your private CodeArtifact repository and an external, public repository, such as npmjs.com or Maven Central. CodeArtifact will then fetch and store packages on demand from the public repository when they're requested by a package manager. This makes it more convenient to consume open-source dependencies used by your application and helps ensure they're always available for builds and development. You can also publish private packages to a CodeArtifact repository. This helps you share proprietary software components between multiple applications and development teams in your organization.
#AWS code build:-AWS CodeBuild is a fully managed build service in the cloud. CodeBuild compiles your source code, runs unit tests, and produces artifacts that are ready to deploy. CodeBuild eliminates the need to provision, manage, and scale your own build servers. It provides prepackaged build environments for popular programming languages and build tools such as Apache Maven, Gradle, and more. You can also customize build environments in CodeBuild to use your own build tools. CodeBuild scales automatically to meet peak build requests.
#AWS code commit:-AWS CodeCommit is a version control service hosted by Amazon Web Services that you can use to privately store and manage assets (such as documents, source code, and binary files) in the cloud.  
#AWS code Deploy:-CodeDeploy is a deployment service that automates application deployments to Amazon EC2 instances, on-premises instances, serverless Lambda functions, or Amazon ECS services. CodeDeploy can deploy application content that runs on a server and is stored in Amazon S3 buckets, GitHub repositories, or Bitbucket repositories. CodeDeploy can also deploy a serverless Lambda function. You do not need to make changes to your existing code before you can use CodeDeploy. 
#AWS code Guru:-Amazon CodeGuru Security is a static application security testing (SAST) tool that combines machine learning (ML) and automated reasoning to identify vulnerabilities in your code, provide recommendations on how to fix the identified vulnerabilities, and track the status of the vulnerabilities until closure. Amazon CodeGuru Profiler helps developers find an application’s most expensive lines of code by helping them understand the runtime behavior of their applications, identify and remove code inefficiencies, improve performance, and significantly decrease compute costs.
#AWS code pipeline:-AWS CodePipeline is a continuous delivery service you can use to model, visualize, and automate the steps required to release your software. You can quickly model and configure the different stages of a software release process. CodePipeline automates the steps required to release your software changes continuously. For information about pricing for CodePipeline
#AWS code star:-AWS CodeStar enables you to quickly develop, build, and deploy applications on AWS. AWS CodeStar provides a unified user interface, enabling you to easily manage your software development activities in one place. With AWS CodeStar, you can set up your entire continuous delivery toolchain in minutes, allowing you to start releasing code faster. AWS CodeStar makes it easy for your whole team to work together securely, allowing you to easily manage access and add owners, contributors, and viewers to your projects. Each AWS CodeStar project comes with a project management dashboard, including an integrated issue tracking capability powered by Atlassian JIRA Software. With the AWS CodeStar project dashboard, you can easily track progress across your entire software development process, from your backlog of work items to teams’ recent code deployments
#AWS x-ray:-(Analyze and debug production and distributed applications)AWS X-Ray provides a complete view of requests as they travel through your application and filters visual data across payloads, functions, traces, services, APIs, and more with no-code and low-code motions.
#Management & Governance:-
#AWS Appconfig:-a capability of AWS Systems Manager, to create, manage, and quickly deploy application configurations. A configuration is a collection of settings that influence the behavior of your application. You can use AWS AppConfig with applications hosted on Amazon Elastic Compute Cloud (Amazon EC2) instances, AWS Lambda, containers, mobile applications, or IoT devices. To view examples of the types of configurations you can manage by using AWS AppConfig. 
#AWS Cloud Development Kit(AWS CDK):-is a framework for defining cloud infrastructure in code (IaC) and provisioning it through AWS CloudFormation..Define your cloud application resources using familiar programming languages.AWS Cloud Development Kit (AWS CDK) accelerates cloud development using common programming languages to model your applications.
#AWS cloudformation(iac):-is a service that helps you model and set up your AWS resources so that you can spend less time managing those resources and more time focusing on your applications that run in AWS. You create a template that describes all the AWS resources that you want (like Amazon EC2 instances or Amazon RDS DB instances), and CloudFormation takes care of provisioning and configuring those resources for you. You don't need to individually create and configure AWS resources and figure out what's dependent on what; CloudFormation handles that
#AWS cloudtrail:-AWS CloudTrail is an AWS service that helps you enable operational and risk auditing, governance, and compliance of your AWS account. Actions taken by a user, role, or an AWS service are recorded as events in CloudTrail. Events include actions taken in the AWS Management Console, AWS Command Line Interface, and AWS SDKs and APIs. Provide Governance,compliance & audit for your AWS Account.(An history of events/API calls made within your AWS Acc)(SDK<CLI<Console,IAm users & IAM roles)   (Cloud Trail Insights:-to Detect Unusual Activity in acc)  (cloud trail events stored for 90days in CT)
#Amazon cloudwatch:-Amazon CloudWatch monitors your Amazon Web Services (AWS) resources and the applications you run on AWS in real time. You can use CloudWatch to collect and track metrics, which are variables you can measure for your resources and applications. The CloudWatch home page automatically displays metrics about every AWS service you use. You can additionally create custom dashboards to display metrics about your custom applications, and display custom collections of metrics that you choose.You can create alarms that watch metrics and send notifications or automatically make changes to the resources you are monitoring when a threshold is breached. For example, you can monitor the CPU usage and disk reads and writes of your Amazon EC2 instances and then use that data to determine whether you should launch additional instances to handle increased load. You can also use this data to stop under-used instances to save money.
#Amazon cloudwatch logs:-You can use Amazon CloudWatch Logs to monitor, store, and access your log files from Amazon Elastic Compute Cloud (Amazon EC2) instances, AWS CloudTrail, Route 53, and other sources.CloudWatch Logs enables you to centralize the logs from all of your systems, applications, and AWS services that you use, in a single, highly scalable service. You can then easily view them, search them for specific error codes or patterns, filter them based on specific fields, or archive them securely for future analysis. CloudWatch Logs enables you to see all of your logs, regardless of their source, as a single and consistent flow of events ordered by time.CloudWatch Logs also supports querying your logs with a powerful query language, auditing and masking sensitive data in logs, and generating metrics from logs using filters or an embedded log format.
#AWS CLI(command line interface):-The AWS Command Line Interface (AWS CLI) is a unified tool that provides a consistent interface for interacting with all parts of Amazon Web Services. AWS CLI commands for different services are covered in the accompanying user guide, including descriptions, syntax, and usage examples..The AWS Command Line Interface (AWS CLI) is a unified tool to manage your AWS services. With just one tool to download and configure, you can control multiple AWS services from the command line and automate them through scripts. 
#AWS systems manager:-is the operations hub for your AWS applications and resources and a secure end-to-end management solution for hybrid and multicloud environments that enables secure operations at scale..(integreated with RDS,REDSHIFT,DOCUMENT DB this rotates DB credentials automatically):-Easily rotate,manage & retrieve DB credentials, API Keys, & other secrets through their lifecycle. 
#Networking & Content Delivery:-
#Amazon API gateway:-Create, maintain, and secure APIs at any scale. Amazon API Gateway is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale. APIs act as the "front door" for applications to access data, business logic, or functionality from your backend services. Using API Gateway, you can create RESTful APIs and WebSocket APIs that enable real-time two-way communication applications. API Gateway supports containerized and serverless workloads, as well as web applications.API Gateway handles all the tasks involved in accepting and processing up to hundreds of thousands of concurrent API calls, including traffic management, CORS support, authorization and access control, throttling, monitoring, and API version management. API Gateway has no minimum fees or startup costs. You pay for the API calls you receive and the amount of data transferred out and, with the API Gateway tiered pricing model, you can reduce your cost as your API usage scales
#Amazon cloudfront:-(Content delivery network)(edge locations). is a globally-distributed network offered by Amazon Web Services, which securely transfers content such as software, SDKs, videos, etc., to the clients, with high transfer speed. It will cache your content in edge locations and decrease the workload, thus resulting in high availability of applications.
#Elastic Load balancing:-Elastic Load Balancing automatically distributes your incoming traffic across multiple targets, such as EC2 instances, containers, and IP addresses, in one or more Availability Zones. It monitors the health of its registered targets, and routes traffic only to the healthy targets. Elastic Load Balancing scales your load balancer capacity automatically in response to changes in incoming traffic.A load balancer accepts incoming traffic from clients and routes requests to its registered targets (such as EC2 instances) in one or more Availability Zones. The load balancer also monitors the health of its registered targets and ensures that it routes traffic only to healthy targets. When the load balancer detects an unhealthy target, it stops routing traffic to that target. It then resumes routing traffic to that target when it detects that the target is healthy again.You configure your load balancer to accept incoming traffic by specifying one or more listeners. A listener is a process that checks for connection requests. It is configured with a protocol and port number for connections from clients to the load balancer. Likewise, it is configured with a protocol and port number for connections from the load balancer to the targets.1)Application LB,2)Network LB,3)Gateway LB,4)Classic LB  
#Amazon Route 53:-A reliable and cost-effective way to route end users to Internet applications. Amazon Route 53 is a highly available and scalable Domain Name System (DNS) web service. Route 53 connects user requests to internet applications running on AWS or on-premises. (simple,weighted,latency,Failover,Geoloaction,Geo proximity,Multivalue)
#Amazon VPC:-With Amazon Virtual Private Cloud (Amazon VPC), you can launch AWS resources in a logically isolated virtual network that you've defined. This virtual network closely resembles a traditional network that you'd operate in your own data center, with the benefits of using the scalable infrastructure of AWS.  Your AWS account includes a default VPC in each AWS Region. Your default VPCs are configured such that you can immediately start launching and connecting to EC2 instances. You can choose to create additional VPCs with the subnets, IP addresses, gateways and routing that you need. A VPC is a virtual network that closely resembles a traditional network that you'd operate in your own data center. After you create a VPC, you can add subnets. A subnet is a range of IP addresses in your VPC. A subnet must reside in a single Availability Zone. After you add subnets, you can deploy AWS resources in your VPC. You can assign IP addresses, both IPv4 and IPv6, to your VPCs and subnets. You can also bring your public IPv4 and IPv6 GUA addresses to AWS and allocate them to resources in your VPC, such as EC2 instances, NAT gateways, and Network Load Balancers. Use route tables to determine where network traffic from your subnet or gateway is directed. A gateway connects your VPC to another network. For example, use an internet gateway to connect your VPC to the internet. Use a VPC endpoint to connect to AWS services privately, without the use of an internet gateway or NAT device. Use a VPC peering connection to route traffic between the resources in two VPCs. Copy network traffic from network interfaces and send it to security and monitoring appliances for deep packet inspection. Use a transit gateway, which acts as a central hub, to route traffic between your VPCs, VPN connections, and AWS Direct Connect connections. A flow log captures information about the IP traffic going to and from network interfaces in your VPC. Connect your VPCs to your on-premises networks using AWS Virtual Private Network (AWS VPN).
#Security,Identity & Compliance:-
#AWS certificate manager(ACM):-Provision and manage SSL/TLS certificates with AWS services and connected resources. Use AWS Certificate Manager (ACM) to provision, manage, and deploy public and private SSL/TLS certificates for use with AWS services and your internal connected resources. ACM removes the time-consuming manual process of purchasing, uploading, and renewing SSL/TLS certificates.
#AWS certificate manager private certificate authority:-Today, we renamed AWS Certificate Manager Private Certificate Authority to AWS Private Certificate Authority (AWS Private CA). This change helps customers differentiate between AWS Certificate Manager (ACM) and AWS Private CA. ACM and AWS Private CA have distinct roles in the process of creating and managing the digital certificates used to identify resources and secure network communications over the internet, in the cloud, and on private networks. ACM manages the lifecycle of certificates: creating, storing, deploying, and managing renewals for AWS services such as Elastic Load Balancing, Amazon CloudFront, and Amazon API Gateway. AWS Private CA enables customers to create customizable private certificates for a broad range of scenarios. AWS services such as ACM, Amazon Managed Streaming for Apache Kafka (MSK), IAM Roles Anywhere and Amazon Elastic Kubernetes Service (EKS) can all leverage private certificates from Private CA. It also supports creating private certificates for Internet of Things (IoT) devices as well as enterprise users, systems and services.This launch coincides with the launch of AWS Private CA’s updated console. The workflow of creating CAs has been simplified to a single page wizard, the listing CAs view now supports filtering and search, and all pages have a sidebar with contextual documentation help. The console also has accessibility improvements to enhance screen reader support and additional tab key navigation for people with motor impairment.
#Amzon cognito:-Amazon Cognito is an identity platform for web and mobile apps. It’s a user directory, an authentication server, and an authorization service for OAuth 2.0 access tokens and AWS credentials. With Amazon Cognito, you can authenticate and authorize users from the built-in user directory, from your enterprise directory, and from consumer identity providers like Google and Facebook.  1)user pool:-Create a user pool when you want to authenticate and authorize users to your app or API. User pools are a user directory with both self-service and administrator-driven user creation, management, and authentication. Your user pool can be an independent directory and OIDC identity provider (IdP), and an intermediate service provider (SP) to third-party providers of workforce and customer identities. Your organization's SAML 2.0 and OIDC IdPs bring workforce identities into Cognito and your app. The public OAuth 2.0 identity stores Amazon, Google, Apple and Facebook bring customer identities.User pools don’t require integration with an identity pool. From a user pool, you can issue authenticated JSON web tokens (JWTs) directly to an app, a web server, or an API. 2)Identity pools:-Set up an Amazon Cognito identity pool when you want to authorize authenticated or anonymous users to access your AWS resources. An identity pool issues AWS credentials for your app to serve resources to users. You can authenticate users with a trusted identity provider, like a user pool or a SAML 2.0 service. It can also optionally issue credentials for guest users. Identity pools use both role-based and attribute-based access control to manage your users’ authorization to access your AWS resources.Identity pools don’t require integration with a user pool. An identity pool can accept authenticated claims directly from both workforce and consumer identity providers.
#AWS identity & access management(IAM):-AWS Identity and Access Management (IAM) is a web service that helps you securely control access to AWS resources. With IAM, you can centrally manage permissions that control which AWS resources users can access. You use IAM to control who is authenticated (signed in) and authorized (has permissions) to use resources. When you create an AWS account, you begin with one sign-in identity that has complete access to all AWS services and resources in the account. This identity is called the AWS account root user and is accessed by signing in with the email address and password that you used to create the account. We strongly recommend that you don't use the root user for your everyday tasks. Safeguard your root user credentials and use them to perform the tasks that only the root user can perform.With AWS Identity and Access Management (IAM), you can specify who or what can access services and resources in AWS, centrally manage fine-grained permissions, and analyze access to refine permissions across AWS. Use IAM to manage and scale workload and workforce access securely supporting your agility and innovation in AWS. 
#AWS key managment service (AWs KMS):-Create and control keys used to encrypt or digitally sign your data. AWS Key Management Service (AWS KMS) lets you create, manage, and control cryptographic keys across your applications and AWS services.
#AWS secrets manager:-AWS Secrets Manager helps you manage, retrieve, and rotate database credentials, application credentials, OAuth tokens, API keys, and other secrets throughout their lifecycles. Many AWS services that use secrets store them in Secrets Manager.Secrets Manager helps you improve your security posture, because you no longer need hard-coded credentials in application source code. Storing the credentials in Secrets Manager helps avoid possible compromise by anyone who can inspect your application or the components. You replace hard-coded credentials with a runtime call to the Secrets Manager service to retrieve credentials dynamically when you need them.With Secrets Manager, you can configure an automatic rotation schedule for your secrets. This enables you to replace long-term secrets with short-term ones, significantly reducing the risk of compromise. Since the credentials are no longer stored with the application, rotating credentials no longer requires updating your applications and deploying changes to application clients.(AWS Credentials,Encryption keys,SSH keys,private keys & certificates)
#AWS security Token srvc(AWS STS):-AWS provides AWS Security Token Service (AWS STS) as a web service that enables you to request temporary, limited-privilege credentials for users. This guide describes the AWS STS API. 
#AWS WAF:-AWS WAF helps you protect against common web exploits and bots that can affect availability, compromise security, or consume excessive resources. With AWS WAF, you can create security rules that control bot traffic and block common attack patterns such as SQL injection or cross-site scripting (XSS).
##storage:-
#ebs:-Amazon Elastic Block Store (Amazon EBS) provides block level storage volumes for use with EC2 instances. EBS volumes behave like raw, unformatted block devices. You can mount these volumes as devices on your instances. EBS volumes that are attached to an instance are exposed as storage volumes that persist independently from the life of the instance. You can create a file system on top of these volumes, or use them in any way you would use a block device (such as a hard drive). You can dynamically change the configuration of a volume attached to an instance. We recommend Amazon EBS for data that must be quickly accessible and requires long-term persistence. EBS volumes are particularly well-suited for use as the primary storage for file systems, databases, or for any applications that require fine granular updates and access to raw, unformatted, block-level storage. Amazon EBS is well suited to both database-style applications that rely on random reads and writes, and to throughput-intensive applications that perform long, continuous reads and writes
#efs:-Amazon Elastic File System (Amazon EFS) provides serverless, fully elastic file storage so that you can share file data without provisioning or managing storage capacity and performance. Amazon EFS is built to scale on demand to petabytes without disrupting applications, growing and shrinking automatically as you add and remove files. Because Amazon EFS has a simple web services interface, you can create and configure file systems quickly and easily. The service manages all the file storage infrastructure for you, meaning that you can avoid the complexity of deploying, patching, and maintaining complex file system configurations.Amazon EFS supports the Network File System version 4 (NFSv4.1 and NFSv4.0) protocol, so the applications and tools that you use today work seamlessly with Amazon EFS. Multiple compute instances, including Amazon EC2, Amazon ECS, and AWS Lambda, can access an Amazon EFS file system at the same time. Therefore, an EFS file system can provide a common data source for workloads and applications that are running on more than one compute instance or server.
#s3:-Amazon S3 is an object storage service that offers industry-leading scalability, data availability, security, and performance. Store and protect any amount of data for a range of use cases, such as data lakes, websites, cloud-native applications, backups, archive, machine learning, and analytics. Amazon S3 is designed for 99.999999999% (11 9's) of durability, and stores data for millions of customers all around the world.
#s3 glacier:-Amazon S3 Glacier (S3 Glacier) is a secure and durable service for low-cost data archiving and long-term backup. With S3 Glacier, you can store your data cost effectively for months, years, or even decades. S3 Glacier helps you offload the administrative burdens of operating and scaling storage to AWS, so you don't have to worry about capacity planning, hardware provisioning, data replication, hardware failure detection and recovery, or time-consuming hardware migrations
#s3 standard:-(used frequently need fast retrive of objs)
#s3 standard-infrequent access(IA):-(used infrequently but need fast retrived of objs in millisec)
#s3 intelligent tiering:-(we dont know when the accessing periode is gng to happen so this is used to automatic life cycle of objs according to use)
#s3 one zone(IA):-(used to save in only in one zone. when the az gone the data will goes)
#s3 glacier instant retrieval:-(long lived archive data accessed once a quater with instant retrival in millisec)
#s3 glacier flexiable retrival:-(long term bups & archives. with retrival option 1 to 12 hours) 1)expedited retriveals(1-5min),2)standard retrival(3-5hrs),3)bulk(5-12hrs)
#s3 glacier deep archive(long term data archiving not accesing frequently & can be retrived within 12hours. used for auditing purpose)
#
##posix= efs (linux used) efs provides a file system interface.it supports millions of files as requested    efs(supports concurrency) and ebs(does not support concurrency) (network attached)
#piops= ebs (persist data)                                               #network attachment
#instance store= emphermal storage once you stop you loss your data      #Hardware                                             instance store (hardware appliance)
#Nitro-based amz ec2 ins with EBS Provisioned IOPs SSD(i01)Vol attached.provisioned 64,000ipos for the vol
#EBS gp3,gp2(general purpose ssd)=3000iops to 16000iops         (3iops for one GiB)  need 40GiB storage & 1000iops  for RDS (cost less)=(provison 334GiB of GP SSD storage for RDS instances)
#EBS io2Block express=256,000
#io2,io3=64000+       Nitro
#EBS throughput optimized HDD(st1):-500 iops
#EBS cold HDD(sc1):- 250 iops
#Least expensive Ebs vol:-cold HDD(sc1)(IA data sequential data access) < Throughput optimized HDD(st1)(intensive wd,FA) < General purpose SSd(gp2)(balances the price and performance) < Provisioned iop(io1)(16000iops)(high performance & low latency)
#
#out-of-scope AWS srvcs & features:-
#AWS Application Discovery srvc:-
#Amazon Appstream 2.0:-
#Amazon connect:-
#AWS Database Migration srvc(DMS):-
#AWS Device Fram:-
#Amazon Elastic Transcoder:-
#Amazon GameLift:- 
#Amazon Lex:-
#Amazon M/c learning(Amazon ML):-
#AWS Managed srvcs(AMS):-
#Amazon Mobile Analytics:-
#Amazon Polly:-
#Amazon Quicksight:-
#Amazon Rekognition:-
#AWS server migration srvscs(AWS SMS):-
#AWS Srvc catalog:-
#AWS shield standard:-
#AWS shield Advanced:-
#AWS snow family:-
#AWS storage gateway:-
#Amzon workMail:-
#Amazon workspaces:-
#
#we need to 40srvcs knowledge.youtube in 28 minutes:-
#cloud:-is a provisioning (renting) resources when you want them & releasing them back when you do not need them? 
#on-demand resources provisioning. 
#Advantages:-lower cost (pay per use),no upfront planning needed,Avoid "undifferentiated heavy lifting."
#challenge:-building cloud enabled applications. 
#
#
#
#
#

#A monolithic application is built as a single unified unit while a microservices architecture is a collection of smaller, independently deployable services.
#ex:-services are catalog,shipping,sellers,search,payment,users they are connected with -->API GW<--1)Mobile2)WEB.  if any service is failed the services are not effected with that so microservices using is great. 

#chat bot is a (Artifical intelligence software). Bot(Analyze the user request and return the response). 
#boto3 is the Amazon Web Services(AWS)  Software Development Kit(SDK) for Python
#API(Application programming interface):-  client(browser)-->(HTTP request)server-->(request)Database 
#                                          Database(respose)-->server(HTTP request)-->client(browser)   in this there server there database but showing the Data to us(by using API).API is also a code by using a server side programming language we write a code that takes the request from another application and this application data process according to that and gives the respose according to the request. 
#Post(Create),Get(Read),Put(Update),Delete(Delete)this are HTTP Method. (API acts as mediator)  one application want to access another applications data or functionlities API used here. (API takes request from one appliaction with the help of API endpoints)  
#In this we 2 APIs 1)Public Apis and 2)private APis
#Rest API:-




#3 4 10 17 18 24 25.
#comparsion between AWS and Azure. 
#Marketplace:-Easy-to-deploy and automatically configured third-party applications, including single virtual machine or multiple virtual machine solutions.
#Compute:-EC2,VMware on cloud AWS,AWS parallel cluster - Azure vms ,Azure VMware solution,Azure cycle cloud
#Auto scaling:-AWS Auto scaling  -  Virtual m/c scale sets,app srvc autoscale.
#Batch Processing:-AWS Batch  -  Azure Batch
#Storage:-s3,EBS,EC2 instance store,EBS provisionedd iops vol,EFS  -  Azure Blob,Azure temporary storage,Azure premium storage,Azure files. 
#Containers and container orchestrators:-ECS,Fargate,ECR,EKS,App Mesh  -  Azure container Apps,Azure container Registry,Azure Kubernetes srvs,Open srvc mesh on AKS. 
#Serverless computing:-AWS Lambda  -  Azure Functions Webjobs
#
#Databases:
#Relational Database:- RDS  -  SQl Database
#Serverless Database:- Amazon Aurora Serverless  -  Azure SQL Database serverless
#NOSQL:-DynamoDB,Simple DB,Amazon DocumentDB,Amazon Neptune  -  Azure cosmos DB
#Caching:-Elasticache,Amazon MemoryDB for Redis  -  cache for Redis
#Database migration:-Database Migration srvc  -  Database Migration srvc. 
# 
#Messaging Components:
#simple Queue srvc(SQS)  -  Queue storage
#simmple notification srvc(SNS)  -  srvc Bus 
#Amzon Event Bridge  -  Event Grid
#Amazon Kinesis  -  Events Hubs
#Amazon MQ  -  Srvc Bus
#
#Networking:
#Cloud virtual networking:-Virtual private cloud(vpc)  -  Virtual network 
#Nat gateways:-Nat gateways  -  Virtual network NAT  (network address translation).
#Cross premise connectivity:-VPN Gateway  -  VPN Gateway
#DNS Management:-Route 53  -  DNS
#DNS based Routing:-Route53  -  Traffic manager
#Dedicated network:-Direct connect  -  Express Route
#Load balancing:-Network load Balancer  -  Load Balancer
#Application LB:-Application LB  -  Application Gateway
#Route table:-Custom Route tables  -  User Defined Routes
#private link:-private link  -  Azure private link
#private Paas connectivity:-VPC endpoints  -  Private Endpoint
#Virtual network peering:-VPC peering  -  VNET peering
#Content delivery networks:-Cloudfront  -  front Door,Azure CDN(content delivery network):-A fast content delivery network srvc that securely delivery data,videos,apps, & APIs to customer globally with low latency,high transfer speeds.  
#Network Monitoring:-VPC Flowlog  -  Azure Network watcher
#
#Marketplace:-AWS Marketplace  -  Azure Marketplace
#AI & ML:-sagemaker-ML,Alexa skills kit-Bot framework,lex-speech srvcs,lex-language understanding,polly Transcribe-speech srvcs,Rekogniton-cognitive srvcs,skills kit-virtual assistant,
#Big data & analytics:-Redshift-synapse Analtics,Lake formation-Data share
#Time series:-Amz Timestream-Azure Data Explorer(or)Azure time series insights
#Big data processing:-EMR-Azure data explorer,EMR-Databricks,EMR-HDinsight,EMR-datalake storage
#Data orchestration/ETL:-Data pipeline glue-Data factory,Glue-Azure purview. 
#Analytics & visualization:-Kinesis analytics-stream analytics(or)Azure data explorer(or)Data lake analytics(or)data lake store,quicksight-powerBI,cloudsearch-cognitive search,Athena-Data lake analytics(or)azure synapse analtics,elastic search-elastic on azure. 
#Devops & app monitoring:-Cw-monitor,code deploy code commit code pipeline-DevOps,developer tools-developer tools,code build-devops pipeline(or)github Actions,cli-cli(or)powershell,eksctl-az aks,aws cloudshell-azure cloudshell,opsworks-automation,cloudformation-resource manager bicep vm extension azure automation. 
#Internet of things(IOT):-IOT Core-IOT Hub,Greengrass-IOT Edge,kinesis firehose kinesis streams-event hubs,IOT things graph-Digital twins.
#Management & goverenance:-AWS Organizations-Management groups,AWS well Archiected tool-Azure well architected review,Trusted Advisor-Advisor,AWS billing & cost management-Azure cost management & billing,cost and usage reports-usage details API,Management console-portal,Applicatiob Discovery srvc-migrate,system manager-monitor,personal health dashboard-resource health,cloud trail-activity log,cw-app insights,config-app change analysis,cost explorer-cost management,control tower-azure lighthouse,resourse groups and tag editor-resource groups & tags,aws app config-azure app configuration,srvc catalog-azure managed apps,SDKs & tools-SDKs & tools. 
#Authentication & authorization:-IAM-AZure Active Directory,IAM-Azure role based access control,organizations-subscription management Azure(RBAC),multi factor authentication-Azure active directory,Directory srvc-Azure active directory domain srvcs,cognito-Azure Active directory external identities,aws config-policy,organizations-management groups. 
#Encryption:-srvr side encrption with s3 key management srvc-azure storage srvc encryption,key management srvc(KMS,HSM),Key Vault. 
#Firewall:-Web app fire wall-web app firewall,aws network firewall-firewall. 
#security:-inspector-defender for cloud,certificate app srvc certificates availablr on the portal,guard duty-microsoft sentinel,Artifact-srvc trust portal,shield-DDos protection srvc. 
#Obj storage:-s3-blob
#virtual srvr disks:-EBS-managed disks
#shared files:-EFS-files
#Archiving & bup:-s3 IA-storage cool tier,S3 glacier- deep archive-storage archive access tier,Bup-Bup. 
#Hybrid storage:-storage GW-storsimple,Datasync-filesync. 
#bulk data transfer:-import/export disk-import/export, import/export(snowball,snowball edge,snowmobile)-Data box
#web apps:-Elastic beanstalk-app srvc,API gw-API management,cloudfront-front door,global accelerator-front door,global accelerator-cross regional LB,lightsail-app srvc,app runner-web app for container,Amplify-static web apps. 
#End-user computing:-workspaces Appstream2.0-Azure virtual Desktop,Worklink-app proxy. 
#
#
#
#
#
#




#Microsoft Azure is a cloud service provider owned and managed by microsoft. It offers various srvcs in the cloud such as compute,storage,Databases and various other domains. It has a Pay-as-you-go model, and is the second largest cloud provider in the market right now.
#Azure course(pay as you go(count in minutes)):- Azure is cloud provider that provides various platform as a srvc(paas) and infra as a srvc(iaas). 
#5% times chepear than other cloud providers,saving through existing Microsoft License,More than 95percent of fortune 500 compines use Microsoft Azure.  Released on (feb-1-2010). its reach is 140+ countries. 
#4 integral Azure srvc domains:-1)Azure Compute(vms,app srvcs, container insts),2)Azure Networking(vnet),3)Azure Storage,4)Azure Database.
#Cloud computing:-is the practice of using remote srvrs on the internet for carrying out a task,rather than using our own computers/srvers.
#Advantages of Cloud Computing:-Little or no investment,More focus on app development,Requires less workforce. 
#Cloud providers:-Google drive(gcp),Netflix(AWS),Amazon(AWS),airbnb,prime video. 
#Cloud Computing Models:-1)Deployment Models(Public cloud(websites),private cloud(DBs),Hibrid Cloud(public and private)),2)Service Model(infra as a srvc(m/c(EC2)),platform as a srvc(Elastic Beanstalk),software as a srvc(total cloud))
#Cloud Providers:-AWS,Microsoft Azure,Google Cloud.

#Azure core Architecture:-
#Azure portal(GUI),Azure powershell(extenstion cmd),Azure CLI(dos cmd),Rest Clients(APIs)
#                     S      D     K   s
#Azure Resource Manager(plays a key deploying and managing the az resources) <----->Authentication
#Data store,web app,V/m,srvc Managment,other srvcs. 

#(300+srvcs)srvcs:-compute,networking,file storage,database+analytics,AI+m/c l,identity,management.  
#1)Compute srvcs(iaas):-1)(Azure Virtual M/c):-are img srvc insts that provide on-demand & scalable computing resources with usage-based pricing. 
#2)Function App(paas)(does backend task) :-is a sol for easily running small piece of code,or "Functions," in the cloud. you can write just the code you need for the problem at hand,without worrying about a whole app or the infra to run it.
#3)App srvc(paas)(used to deploy an app):-fully managed srvc that integrates Microsoft Azure website,Mobile srvc, & Biztalk srvcs into a single srvc.
#4)Azure Kubernetes srvc(AKS):-is a managed container orchestration srvc, based on the open source Kubernetes system, which is available on the Microsoft Azure public cloud.

#Hands on:-create a VM on Azure:-
#go to resource group and create a resource group Demo-Env,select region,create,goto vartial m/c,select resource group,name,region,no infra,ubuntu,change size less,select,ssh public key or password,allow ssh,http,create.(this charges 50 piece per hour)and now go inside the Env select as ip connect with putty ip and paste ssh connect and give name of m/c. sudo apt-get update,sudo apt-get install apache2,-y,Now copy ip and search in browser we get apache2 ubuntu default page. cd /var/www/html,ls,sudo mv index.html l.html,sudo nano index.html,writ html code,ls. just refresh the browser we get our code runner. (here we created a linux vm and hosted a website on a server)


#Networking srvcs:-1)virtual Networks:-(VNet)is a representation of your own network in the cloud. it is a logical isloation of the Azure cloud dedicated to your subscription. Each VNet you create has its own CIDR block, & can be linked to other VNets & on-premises networks as long as CIDR blocks do not overlap.
#2)Load Balancers:-Is a layer-4(TCP,UDP)Load balancer that provides high availability by distributing incoming traffic among healthy VMs.
#3)Application Gateway:-Is a web traffic load balancer that enables you to manage traffic to your web apps. This type of routing is known as application layer(osl layer7)load balancing. 
#4)DNS Zones:-Is a resource that contains the DNS records for a domain name. you can use Azure DNS to host a DNS zone & manage the DNS records for a domain in Azure. 
#4)CDN Profiles(content delivery network(CDN)):-is a global CDN sol for delivering high-bandwidth content. with AZUre CDN,you can cache static objs loaded from Azure Blob storage, a web app, or any publickly accessible web server,by using the closet point of presence(pop)server. 

#Storage srvcs:-1)Blob(binary large objects):-storage is a srvc for storing large amounts of unstructured obj data, such as text or binary data. common uses of blob storage include: serving imgs or documents directly to a browser. storing files for distributed access. streaming video & auido.
#2)Azure Files:-fully managed file shares in that are accessible via the industry standard srvr msg block(SMB) protocol. Azure file shares can be mounted concurrently by cloud or on-premises deployments of windows,linux,& macos.
#3)Tables:-stores large amounts of structured data. The srvc is nosql datastore which accepts authenticated calls from inside & outside the Azure Cloud. 
#4)Queues:-stores large no.of msgs that can be accessed from anywhere in the via authenticated calls using HTTP or HTTPS. A single msg 64KB in size & can contain millions of msgs, upto total capacity limit.
#5)Data Lake storage:-this enables you to capture data of any size,type, & ingestion speed in one single place for operational & exploratory analytics.
#6)Data Box:-Move stored or in-flight data to Azure quickly & cost-effiectively.(this is offline devices to move data to Azure) move data to & fro over the network.

#Hands on:-Goto storage accounts,add,resource group,name,region,standard,hot,create,go inside,create a container,name it,ok,go inside,upload some files init,we get URL to access it(but have to give public),ok,we can see the file by URL.   

#Database + Analytics srvcs:-1)Sql DB(paas srvc):-Is an intelligent,scalable,cloud DB srvc that provides the broadest SQL srvr engine compatibility & upto a 212% return on investment.
#CosmosDB(no SQL):-fully managed srvc with turnkey global distribution & transparent multi-master replication.elastic scaling of throughput & storage. 
#Data Factory(ETL srvc):-fully managed srvc for composing data storage,processing & movement srvcs into streamlined,scalable & reliable data production pipelines. 
#Event Hubs:-fully managed,real-time data ingestion srvc i.e., simple,trusted & scalable. stream millions of events per second from any source to build dynamic data pipelines & immeddiatley respond to business challenges.
#Data Lake Analytics:-Is a distributed, cloud-based data processing architecture offered by microsoft in Azure cloud. this based on YARN, the same as the open-source Hadoop platform. this is paired with Azure data lake store, A cloud-based storage platform designed for big data analtics. 

#AI+Machine Learning:-1)Cognitive srvcs:-Are APIs,SDKs, & srvcs available to help developers build intelligent apps without having direct AI or data science skills or knowledge.this srvc enable developers to easily & cognitive features into their apps. 
#2)Bot Srvcs:-is microsoft's AI chatbot offered as a srvc on the azure cloud srvc marketplace. This offers the ability to add intelligent agents that are capable of conersation with having to commit the resources to develop one's own AI. 
#3)M/c Learning Studio:-is a collaborative, drag-and-drop tool you can use to build,test,& deploy predictive analytics sol on your data. M/C l studio publishes models as web srvcs that can easily be consumed by custom apps or BI tools such as Excel. 

#Identity srvcs:-is AZure Active Directory(AD):-fully managed mulit-tenant srvc from microsoft that offers identity & access capabilities for apps running in Microsoft Azure & for apps running in an on-premises env.
#Azure Active Directory:-users & Groups (adding a user and giving access to users and groups)

#Management services :-1)log analytics:-Log data collected by Azure Monitor is stored in a Log Analytics workspace,which is based on Azure Data explorer. It collects telemetry from a variety of sources & uses the kusto query language used by data explorer to reteireve & analyze data. 
#2)Cost management+Billing:-Is a native solution. It helps you analyze costs,create & manage budgets,export data,& review & act on optimization recommendations to save money. 
#3)Automation Acc:-delivers a cloud-based automation and configuration srvc that provides consistent management across your azure & azure env. it consists of process automation,update management, & configuration features. 
#4)Metrics:-this available for interactive analysis in the azure portal with metrics explorer. They can be added to an Azure dashboard for visualization in combination with other data & used for near-real time alerting. Read more about azure monitor. Metrics including their sources of data in metrics in Azure monitor. 

#Hands-on:-Architecting an Application on Azure:

#











# Consolidate Finance team approved for everyone in the team according to cc and feedback will be sent to the issue provider. 
# Consolidated Admin team requests from the  AC to everything that is related to admin team and also who is assigned to it resolving date and expected time with feedback after issue is resolved. 
# Delta internal forum(like social media) for specific activites, concerns and any thing related to the employees. 
#chat bot
#Azure Fundamantels
#GCP (multi cloud)


